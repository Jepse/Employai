
# LLM + Autogen + MemGPT + Python = Employai ⭐
by Jean-Philippe Simard assisted by GPT-4

Every day, the evolution of artificial intelligence takes an exponential leap. This document introduces a concept that combines the latest technologies and libraries to achieve "Employai"(pronounced like the french word "Employé"), an innovative combination of LLM ("GPT, Llama, others"), Microsoft Autogen, MemGPT, and Python.

AutoGen is a framework developed by Microsoft to simplify the orchestration, optimization, and automation of workflows based on Large Language Models (LLM). It allows for the creation of next-generation applications based on multi-agent conversations with minimal effort. It provides customizable and conversational agents that integrate the capabilities of the most advanced LLMs, such as GPT-4, while overcoming their limitations by incorporating interactions with humans and tools. AutoGen is the result of collaborative research between Microsoft, Penn State University, and the University of Washington. For more information, you can refer to the official article: [Microsoft's Official Article on AutoGen](https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/) and [Autogen GitHub](https://github.com/microsoft/autogen).

MemGPT is a system that intelligently manages different levels of memory in LLMs to efficiently provide an extended context in the limited context window. For instance, MemGPT knows when to push critical information to a vector database and when to retrieve it later, allowing for ongoing conversations. The concept is inspired by the hierarchical memory systems of traditional operating systems. It uses a technique called virtual context management to handle data movements between fast and slow memory. The code and data for MemGPT experiments are available on their official website and GitHub repository.

By combining AutoGen's orchestration capabilities with the natural language processing power of LLMs, MemGPT's memory, and using Python as a scripting language to link these components, one can create a robust and versatile agent capable of handling a variety of complex tasks while interacting smoothly and naturally with users. The vision for Employai is the complete integration of this concept with "open source" models (GPT-3, HuggingFace Transformers, etc.) offline. Thus, a high-performance computer would host an LLM that would serve the agents required by a local API. This would reduce the operating costs of the models, increase information security, and allow the models to evolve in their respective environments. The integration of VoIP (Voice over IP) could enable communication between humans and LLMs. This would allow them to function at the same level as a human employee working remotely. [Employai GitHub Repository](https://github.com/Jepse/employai).

# FR

Chaque jours l’évolution de l’intelligence artificielle fait un bond exponentiel. Le présent document introduit un concept qui combine les technologies et librairies les plus récentes pour obtenir “Employai”(prononcé "Employé") 
une combinaison innovante de LLM("GPT, Llama, autres"), Microsoft Autogen, MemGPT et Python.


AutoGen est un cadre développé par Microsoft pour simplifier l'orchestration, l'optimisation et l'automatisation des flux de travail basés sur les Modèles de Langage de Grande Taille (LLM). Il permet de créer des applications de nouvelle génération basées sur des conversations multi-agents avec un effort minimal. Il offre des agents personnalisables et conversables qui intègrent les capacités des LLMs les plus avancés, tels que GPT-4, tout en surmontant leurs limitations en intégrant des interactions avec des humains et des outils.
AutoGen est le résultat de recherches collaboratives entre Microsoft, la Penn State University et l'Université de Washington. Pour plus d'informations, vous pouvez consulter l'article officiel:
https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/ Autogen GitHub https://github.com/microsoft/autogen 
MemGPT est un système qui gère intelligemment différents niveaux de mémoire dans les LLMs afin de fournir efficacement un contexte étendu dans la fenêtre de contexte limitée. Par exemple, MemGPT sait quand pousser des informations critiques vers une base de données vectorielle et quand la récupérer plus tard, permettant des conversations perpétuelles. Le concept est inspiré des systèmes de mémoire hiérarchiques des systèmes d'exploitation traditionnels. Il utilise une technique appelée gestion de contexte virtuel pour gérer les mouvements de données entre la mémoire rapide et lente.
Le code et les données pour les expériences de MemGPT sont disponibles sur leur site officiel et leur répertoire GitHub.

En combinant les capacités d'orchestration d'AutoGen avec la puissance de traitement du langage naturel des LLMs, la mémoire de MemGPT, et en utilisant Python comme langue de script pour lier ces composants, on peut créer un agent robuste et polyvalent capable de gérer une variété de tâches complexes tout en interagissant de manière fluide et naturelle avec les utilisateurs. 
La vision pour Employai c’est l’integration complète de ce concept avec les modèles “open source” (GPT-3, HuggingFace Transformers, etc) hors ligne. Donc une ordinateur performante serais l’hôte d’un LLM qui lui servirais les agents requis par un api local. Ceci réduirait les couts d’exploitation des modèles, augmenterais la sécurité de l’information et permettrais au modèles d’évoluer dans leurs environnements respectifs.
L’intégration de VoIP(Voix sur IP) pourrais permettre la communication entre humains et LLM. Cela permettrais a ceux ci d’être fonctionnel au même niveau qu’un employé humain qui travail à distance.
